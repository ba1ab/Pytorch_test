{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab6bbb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "\n",
    "LAMBDA_E = 0.5\n",
    "LAMBDA_T = 0.5\n",
    "MIN_SIZE = 1 # MB  1024 * 8 \n",
    "MAX_SIZE = 50 # MB 1024 * 8\n",
    "MIN_CYCLE = 300 # \n",
    "MAX_CYCLE = 1000\n",
    "MIN_DDL = 0.1 # seconds\n",
    "MAX_DDL = 1 # seconds\n",
    "MIN_RESOURCE = 0.4 # GHz\n",
    "MAX_RESOURCE = 1.5 # GHz\n",
    "MIN_POWER = 1 # dB\n",
    "MAX_POWER = 24\n",
    "CAPABILITY_E = 4 # GHz \n",
    "K_ENERGY_LOCAL = 5 * 1e-27\n",
    "\n",
    "MIN_ENE =0.5\n",
    "MAX_ENE = 3.2\n",
    "HARVEST_RATE = 0.001\n",
    "W_BANDWIDTH = 40\n",
    "\n",
    "K_CHANNEL = 10\n",
    "S_E = 400\n",
    "N_UNITS = 8\n",
    "MAX_STEPS = 10\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f7310b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class uavENV():\n",
    "\n",
    "    \n",
    "\n",
    "    def __init__(self, n_agents):\n",
    "        \n",
    "        self.state_size = 7\n",
    "        self.action_size = 3\n",
    "        self.n_agents = n_agents\n",
    "        self.W_BANDWIDTH = W_BANDWIDTH\n",
    "\n",
    "        self.S_power = np.zeros(self.n_agents)\n",
    "        self.initial_energy = np.zeros(self.n_agents)\n",
    "        self.S_energy = np.zeros(self.n_agents)\n",
    "        self.S_gain = np.zeros(self.n_agents)\n",
    "        self.S_size = np.zeros(self.n_agents)\n",
    "        self.S_cycle = np.zeros(self.n_agents)  \n",
    "        self.S_ddl = np.zeros(self.n_agents)\n",
    "        self.S_res = np.zeros(self.n_agents)\n",
    "        self.action_lower_bound = [0,  0.01, 0.01] \n",
    "        self.action_higher_bound = [1, 1, 1]\n",
    "        for n in range(self.n_agents):\n",
    "            self.S_size[n] = np.random.uniform(MIN_SIZE, MAX_SIZE)\n",
    "            self.S_cycle[n] = np.random.uniform(MIN_CYCLE, MAX_CYCLE)\n",
    "            self.S_ddl[n] = np.random.uniform(MIN_DDL, MAX_DDL)\n",
    "            self.S_res[n] = np.random.uniform(MIN_RESOURCE, MAX_RESOURCE)\n",
    "\n",
    "    \n",
    "    \n",
    "    def reset(self):\n",
    "        self.step = 0\n",
    "        for n in range(self.n_agents):\n",
    "            self.S_size[n] = np.random.uniform(MIN_SIZE, MAX_SIZE)\n",
    "            self.S_cycle[n] = np.random.uniform(MIN_CYCLE, MAX_CYCLE)\n",
    "            self.S_ddl[n] = np.random.uniform(MIN_DDL, MAX_DDL)\n",
    "            self.S_energy[n] = deepcopy(self.initial_energy[n])\n",
    "        self.S_energy = np.clip(self.S_energy, MIN_ENE, MAX_ENE)\n",
    "        self.state = np.array([self.S_power[n], self.S_gain[n], self.S_energy[n], self.S_size[n], self.S_cycle[n], self.S_ddl[n], self.S_res[n] for n in range(self.n_agents)])\n",
    "        return self.state\n",
    "    \n",
    "    \n",
    "    \n",
    "    def step(self, action):\n",
    "        A_decision = np.zeros(self.n_agents)\n",
    "        A_res = np.zeros(self.n_agents)\n",
    "        A_power = np.zeros(self.n_agents)\n",
    "        for n in range(self.n_agents):\n",
    "            A_decision[n] = action[n][0]\n",
    "            A_res[n] = action[n][1] * self.S_res[n] * 10 ** 9\n",
    "            A_power[n] = action[n][2] * 10 ** ((self.S_power[n]-30)/10)\n",
    "\n",
    "        # 任务时间计算\n",
    "        x_n = A_decision\n",
    "        DataRate = self.W_BANDWIDTH * 10 ** 6  * np.log(1 + A_power * 10 **(self.S_gain/10)) / np.log(2)\n",
    "        DataRate = DataRate / K_CHANNEL\n",
    "        Time_proc = self.S_size*8*1024*self.S_cycle / (CAPABILITY_E*10**9)\n",
    "        Time_local = self.S_size*8*1024*self.S_cycle / A_res\n",
    "        Time_max_local = self.S_size*8*1024*self.S_cycle / (MIN_RESOURCE*10**9)\n",
    "        Time_off = self.S_size*8*1024/ DataRate\n",
    "        for i in range(self.n_agents):\n",
    "            if x_n[i] == 2:\n",
    "                Time_off[i] = MAX_DDL\n",
    "                x_n[i] = 1\n",
    "        Time_finish = np.zeros(self.n_agents)\n",
    "        SortedOFF = np.argsort(Time_off)\n",
    "        MECtime = np.zeros(N_UNITS)\n",
    "        counting = 0\n",
    "        for i in range(self.n_agents):\n",
    "            if x_n[SortedOFF[i]] == 1 and counting < N_UNITS:\n",
    "                Time_finish[SortedOFF[i]] = Time_local[SortedOFF[i]] + Time_proc[SortedOFF[i]]\n",
    "                MECtime[np.argmin(MECtime)] = Time_local[SortedOFF[i]] + Time_proc[SortedOFF[i]]\n",
    "                counting += 1\n",
    "            elif x_n[SortedOFF[i]] == 1:\n",
    "                for j in range(i):\n",
    "                    if x_n[SortedOFF[j]] == 1:\n",
    "                        MECtime[np.argmin(MECtime)] += Time_proc[SortedOFF[j]]\n",
    "                Time_finish[SortedOFF[i]] = max(Time_off[SortedOFF[i]], np.min(MECtime)) + Time_proc[SortedOFF[i]]\n",
    "                MECtime[np.argmin(MECtime)] = max(Time_off[SortedOFF[i]], np.min(MECtime)) + Time_proc[SortedOFF[i]]\n",
    "        Time_n = (1-x_n) * Time_local + x_n * (Time_off + Time_proc)\n",
    "\n",
    "        Time_n = [min(t,MAX_DDL) / MAX_DDL for t in Time_n]\n",
    "        T_mean = np.mean(Time_n)\n",
    "\n",
    "        # 能耗计算\n",
    "        Energy_local = K_ENERGY_LOCAL * self.S_size *8*1024 * self.S_cycle * A_res\n",
    "        Energy_max_local = K_ENERGY_LOCAL * self.S_size *8*1024* self.S_cycle * (self.S_res*10**9)\n",
    "        Energy_off = A_power * Time_off\n",
    "        Energy_n = (1-x_n) * Energy_local + x_n * Energy_off\n",
    "        self.S_energy = np.clip(self.S_energy - Energy_n*1e-6 + np.random.normal(HARVEST_RATE, 0, size=self.n_agents)*1e-6, 0, MAX_ENE)\n",
    "        for i in range(x_n.size):\n",
    "            if self.S_energy[i] <= 0:\n",
    "                Time_n[i] = MAX_DDL / MIN_DDL\n",
    "        \n",
    "        # 奖励计算\n",
    "        \n",
    "        Time_penalty = np.maxmum((Time_n - self.S_ddl/MAX_DDL), 0)\n",
    "        Energy_penalty = np.maximum((MIN_ENE - self.S_energy), 0)*10**6\n",
    "        time_penalty_nozero_count = np.count_nonzero(Time_penalty)/self.n_agents\n",
    "        energy_penalty_nozero_count = np.count_nonzero(Energy_penalty)/self.n_agents\n",
    "        Reward = -1*(LAMBDA_E * np.array(Energy_n) + LAMBDA_T * np.arrat(Time_n)) -1*(LAMBDA_E *np.array(Energy_penalty) + LAMBDA_T*np.array(Time_penalty))\n",
    "        Reward = np.ones_lik(Reward) * np.sum(Reward)\n",
    "        for n in range(self.n_agents):\n",
    "            self.S_size[n] = np.random.uniform(MIN_SIZE, MAX_SIZE)\n",
    "            self.S_cycle[n] = np.random.uniform(MIN_CYCLE, MAX_CYCLE)\n",
    "            self.S_ddl[n] = np.random.uniform(MIN_DDL, MAX_DDL - MIN_DDL/10)\n",
    "        \n",
    "        # 状态更新\n",
    "        self.state = np.array([self.S_power[n], self.S_gain[n], self.S_energy[n], self.S_size[n], self.S_cycle[n], self.S_ddl[n], self.S_res[n] for n in range(self.n_agents)])\n",
    "        self.step += 1\n",
    "        done = False\n",
    "        if self.step >= MAX_STEPS:\n",
    "            self.step = 0\n",
    "            done = True\n",
    "        return self.state, Reward, done, energy_penalty_nozero_count, time_penalty_nozero_count\n",
    "            \n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b7f155af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10  7  5 10 11 48 20 65 92 49 30 13 57 80]\n"
     ]
    }
   ],
   "source": [
    "env=uavENV()\n",
    "print(env)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "db20c95c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13 96]\n",
      "96\n"
     ]
    }
   ],
   "source": [
    "UAV_energy_list = np.random.randint(0, 101, 2)\n",
    "print(UAV_energy_list)\n",
    "\n",
    "print(UAV_energy_list[1])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
